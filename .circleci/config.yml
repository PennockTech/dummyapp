version: 2

# Assumed environment variables from config:
#   HEROKU_API_KEY:  an auth token for Heroku, needed to configure docker push
#   DOCKERHUB_USER:  Docker Hub user to push to Hub as
#   DOCKERHUB_PASS:  A token or somesuch to authenticate to Docker Hub


defaults: &defaults
  docker:
    # The image is the control image for Circle CI, the env
    # DOCKER_BUILDER_IMAGE is the one we launch for invoking Go.
    # Less variance leads to less to debug.
    - image: &basic_image
        pennocktech/ci:purple
      environment:
        DOCKER_BUILDER_IMAGE: *basic_image
        # Rather than hard-code DOCKER_BUILDER_GOLANG_VERSION we can extract
        # it automatically:
        EXTRACT_GO_VERSION_FROM_LABEL: "com.pennock-tech.versions.go"
        GO_PARENTDIR: "/home/ci/"
        #
        DOCKER_PROJECT: "pennocktech/dummyapp"
        BUILD_TAGS: "heroku zerolog"
        BUILDER_SYSTEM: "circleci"

# <https://circleci.com/blog/how-to-build-a-docker-image-on-circleci-2-0/>
#  -- the loose gameplan, reworked a fair bit, especially since we have
#     multi-stage to deal with, so the caching would have been wrong for us
#
# <https://circleci.com/docs/2.0/building-docker-images/>
#  -- the default image is currently 17.03.0-ce but multi-stage builds require
#     at least 17.05, so we override; we only _need_ to override for the build
#     stage, but I don't want to debug brokenness when multiple versions of
#     Docker are used at different stages, so we use a consistent image.
#
#     And remember that there's a distinct shortage of Variable Interpolation
#     which we can use.  There are 'references', which are YAML.
#     It seems one way to organize this, used by circle themselves, is to declare
#     a dummy top-level key "references", to hold variables, where the second-level
#     key doesn't matter, but the &name is what's used.  See the common `&defaults`
#     model, which we were already using, but extended a bit more.

references:
  remote_docker_version: &remote_docker_version
    17.11.0-ce

  project_working_dir: &project_working_dir
    ~/go/src/go.pennock.tech/dummyapp

  # We don't need our unusual Docker image pulled for the deploy steps, it will
  # rarely already be on the machine, since the deploy is unlikely to happen on
  # the same host as the build.
  #
  # We pretty much need: a shell, the docker command, whatever the
  # setup_remote_docker tag requires.  Grab a current Docker, since the
  # highest version documented by Circle CI for remote Docker (17.11) is
  # too old to be listed in the Supported tags for docker images.
  # So we'll have 18.02 client talking to 17.11 server within CI, and
  # whatever the external repositories are.
  deployer_image: &deployer_image
    docker:
      - image: docker:18.02.0-ce-git

  gcloud_image: &gcloud_image
    docker:
      # :alpine and :slim are smaller, but omit the docker command
      - image: google/cloud-sdk:latest

  # beware these are also embedded in run command-lines:
  image_persist_path: &image_persist_path
    /tmp/persist/docker-layers.tar
  persist_directory: &persist_directory
    /tmp/persist



jobs:
  build:
    <<: *defaults
    working_directory: *project_working_dir
    steps:
      - checkout
      - setup_remote_docker:
          version: *remote_docker_version

      # FIXME: have a git repo to hold the vendored dependencies, or perhaps
      # do cache these, although note that means restore-cache before checkout
      - run:
          name: Install dependencies
          command: dep ensure -v -vendor-only

      # For languages where there are many slow build steps, or when installing
      # an OS package as part of the final image, a build-cache makes sense.
      # In our case though, we build using an image which has already been
      # pulled from the repository at least once (because we're running in it
      # now, assuming docker.environment.DOCKER_BUILDER_IMAGE == docker.image)
      # and all the content to be built is either in the repo or should be
      # (the dependencies step above still needs a little work).
      # So all that the cache does is serialize to cache something which can
      # as quickly be got from somewhere else.  And the OS image is _huge_, this
      # is not fast.
      #
      # Note too that caching the built image from a Dockerfile does not
      # cache all the intermediate steps used to create the target, so there's
      # no re-use, so not much point to it.

      # If you had something heavyweight though, then you would use a
      # "restore_cache:", then the "fetch whatever's newer than what I have",
      # then "save_cache" here.  Be sure to version the cache keys, and put the
      # path in the references section above, to catch typos.

      - run:
          name: Build Docker image
          command: ./build/build.with-docker.sh
          environment:
            DIND_PERSIST_FILE: *image_persist_path
            VERBOSE: "2"

      - run:
          name: Create persisted commands for deploy steps
          command: ./build/create-persist-commands.sh
          environment:
            PERSIST_DIR: *persist_directory
            VERBOSE: "2"
            RETAG: "heroku"

      # Run tests here

      # *** Deploys ***
      #
      # Note that to make the Docker image available to a later workflow step,
      # we need to manually save the exported layer cache for the final
      # image.
      #
      # This is so unclean.
      #
      # But it's more important to not have a deploy failure invalidate the
      # result of the build step, assuming all tests passed.  Deploys should
      # be resumable.
      #
      # And bonus, we can declare an artifact and have the image be pullable
      # via HTTP for manual import!  But we can't retrieve later artifacts
      # without manually glueing Circle CI tokens back in for use within Circle
      # CI, and we've got too much Inception going on already with
      # docker-in-docker, so I don't want to do that.  Thus we stick with
      # "persist" for that.

      - store_artifacts:
          path: *image_persist_path
          destination: docker-image.tar

      - persist_to_workspace:
          root: *persist_directory
          paths: .


  # For the deploy targets, note that unless we checkout again, we don't have
  # the Makefile; we can only persist one root to the workspace, but we don't
  # want to embed in knowledge of where in the Docker image '~' is, since it
  # can vary between builders.
  #
  # While we've built the image with multiple tags, for pushing to Heroku
  # those don't matter, we can just push latest since we also built with that.
  # But for pushing to Docker Hub, the actual tag is precious.
  #
  # Thus we've made sure that the actual deploy steps in GNUmakefile also have
  # standalone modes, with no dependencies; we can use "make -n step-foo" to
  # get the actual deploy instructions emitted, keeping the GNUmakefile as the
  # single source of truth for that.

  deploy_heroku:
    <<: *defaults
    <<: *deployer_image
    steps:
      - setup_remote_docker:
          version: *remote_docker_version
      - run:
          name: Docker Login to Heroku registry
          command: docker login -u _ -p "${HEROKU_API_KEY}" registry.heroku.com
      - attach_workspace:
          at: *persist_directory
      - run:
          name: Load Docker image from persisted workspace
          command: docker load -i /tmp/persist/docker-layers.tar
      - run:
          name: Deploy docker image to Heroku
          command: /tmp/persist/heroku-deploy.sh

  push_docker_hub:
    <<: *defaults
    <<: *deployer_image
    steps:
      - setup_remote_docker:
          version: *remote_docker_version
      - run:
          name: Docker Login to Docker Hub
          command: docker login -u "${DOCKERHUB_USER}" -p "${DOCKERHUB_PASS}"
      - attach_workspace:
          at: *persist_directory
      - run:
          name: Load Docker image from persisted workspace
          command: docker load -i /tmp/persist/docker-layers.tar
      - run:
          name: Push docker image to Docker Hub
          command: /tmp/persist/docker-hub-deploy.sh

  # TODO: setup a project and have this running in GKE, instead of just available from GCR
  push_gce_registry:
    <<: *defaults
    <<: *gcloud_image
    steps:
      - setup_remote_docker:
          version: *remote_docker_version
      - run:
          name: gcloud status report for logs
          command: gcloud info; gcloud auth list
      - attach_workspace:
          at: *persist_directory
      - run:
          name: GCR login
          command: |
            printf '%s\n' "${GCLOUD_AUTH_ENCODED}" | base64 --decode --ignore-garbage > "${HOME}/gcloud-service-key.json"
            gcloud auth activate-service-account --key-file ${HOME}/gcloud-service-key.json
            /tmp/persist/gcloud-login.sh
      - run:
          name: Load Docker image from persisted workspace
          command: docker load -i /tmp/persist/docker-layers.tar
      - run:
          name: Push docker image to GCE
          command: /tmp/persist/gcr-deploy.sh


workflows:
  version: 2

  build_and_deploy:
    jobs:
      - build
      - deploy_heroku:
          context: heroku-and-dockerhub
          requires:
            - build
          filters:
            branches:
              only:
                - master
      - push_docker_hub:
          context: heroku-and-dockerhub
          requires:
            - build
          filters:
            branches:
              ignore:
                - /.*nohub.*/
      - push_gce_registry:
          context: google-dummyapp
          requires:
            - build
          filters:
            branches:
              ignore:
                - /.*nogcloud.*/

# vim: sw=2 :
